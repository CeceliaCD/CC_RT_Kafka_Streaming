version: '3.8'

services:

  zookeeper:
    image: bitnami/zookeeper:3.9
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes

  kafka:
    image: bitnami/kafka:3.9
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      - KAFKA_BROKER_ID=1
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092
      - KAFKA_CFG_LISTENERS=PLAINTEXT://0.0.0.0:9092
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT
      - KAFKA_CFG_INTER_BROKER_LISTENER_NAME=PLAINTEXT
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_ENABLE_KRAFT=no
    depends_on:
      - zookeeper

  spark-master:
    image: bitnami/spark:3.5
    container_name: spark-master
    environment:
      - SPARK_MODE=master
    ports:
      - "7077:7077"
      - "8080:8080"
    volumes:
      - ./streaming-app:/opt/streaming-app
    depends_on:
      - kafka
      - flask-exporter

  spark-worker:
    image: bitnami/spark:3.5
    container_name: spark-worker
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
    depends_on:
      - spark-master
    ports:
      - "8081:8081"

  producer:
    build: ./streaming-app/producer
    container_name: amazon-shopping-sim-producer
    depends_on:
      - kafka

  consumer:
    build: ./streaming-app/consumer
    container_name: kafka-consumer
    depends_on:
      - kafka

  flask-exporter:
    build: ./flask-exporter
    container_name: flask-exporter
    ports:
      - "8000:8000"
    depends_on:
      - kafka

  prometheus:
    image: prom/prometheus
    container_name: prometheus
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
    ports:
      - "9090:9090"

  grafana:
    image: grafana/grafana
    container_name: grafana
    ports:
      - "3000:3000"
    depends_on:
      - prometheus

  spark-streaming-job:
    build:
      context: streaming-app/spark-streaming
      dockerfile: Dockerfile
    image: amazon-spark-streaming-job:3.5
    container_name: amazon-spark-streaming-job
    user: "501:20"
    entrypoint:
      - /opt/bitnami/spark/bin/spark-submit
      - --master
      - spark://spark-master:7077
      - --deploy-mode
      - client
      - --conf
      - spark.jars.ivy=/tmp/.ivy2
      - --conf
      - spark.hadoop.security.authentication=NOSASL
      - --conf
      - spark.authenticate=false
      - --conf
      - spark.authenticate.enableSaslEncryption=false
      - --conf
      - spark.hadoop.fs.hdfs.impl.disable.cache=true
      - --packages
      - org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0,org.apache.kafka:kafka-clients:3.5.1,org.mongodb.spark:mongo-spark-connector_2.12:3.0.1
      - --conf
      - spark.jars.ivy=/tmp/spark-ivy
      - /opt/streaming-app/spark-streaming/amazon_spark_streaming_job.py
    environment:
      - USER=sparkuser
      - LOGNAME=sparkuser
      - HADOOP_USER_NAME=sparkuser
      - HOME=/tmp
    volumes:
      - ./my_passwd:/etc/passwd:ro
      - ./streaming-app:/opt/streaming-app
      - ./jars:/opt/streaming-app/jars
      - ivy-cache:/tmp/.ivy2
      - ./logs:/opt/bitnami/spark/logs
    depends_on:
      - kafka
      - flask-exporter

volumes:
  ivy-cache: